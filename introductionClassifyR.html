<!DOCTYPE html>
<html>
  <head>
    <title>Classification for High-dimensional Biomedical Data Utilising ClassifyR</title>
    <meta charset="utf-8">
    <meta name="author" content="Dr. Dario Strbenac and Dr. Shila Ghazanfar   School of Mathematics and Statistics, University of Sydney, N.S.W, Australia" />
    <meta name="date" content="2018-11-29" />
    <link href="introductionClassifyR_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="styling/sydneyFonts.css" type="text/css" />
    <link rel="stylesheet" href="styling/sydneyTheme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Classification for High-dimensional Biomedical Data Utilising ClassifyR
### Dr. Dario Strbenac and Dr. Shila Ghazanfar <br> School of Mathematics and Statistics, University of Sydney, N.S.W, Australia
### 29 November 2018

---


## Roadmap

* 30 minutes - Introduction to ClassifyR

  * Varieties of Input Data
  * Cross-validation Overview
  * Provided Feature Selection and Classification Functions
  * Classification Performance Evaluation
  * Support and Installation

* 50 minutes - Interactive Session Classifying AML Treatment Resistance

* 10 minutes - Concluding Remarks

---

class: segue-red

# Part 1: Introduction to ClassifyR

---

## Motivation for Development

* A standardised form of cross-validation is not provided by a standard R installation. Often, researchers code their own cross-validation loop for each project, allowing opportunities for implementation inconsistencies to occur.

--

* A few frameworks have been developed (e.g. `MCRestimate`, `MLInterfaces`, `caret`) but their focus is on classification, so evaluation of the features and predictions is not comprehensive.

--

* Input formats of existing classification frameworks don't seamlessly handle new data containers for omics data sets, such as `MultiAssayExperiment`.

--

* ClassifyR provides a standardised cross-validation framework with a focus on biologically motivated performance evaluation and seamlessly operates on `DataFrame` and `MultiAssayExperiment` S4 containers across mulitple cores using `BiocParallel` functionality.

---

## Varieties of Input Data

Three kinds of data sets can be used as input.

.center[
![](images/dataTypesSingle.png)
]

---

.center[
![](images/dataTypesMulti.png)
]

---

## DataFrame Container

`ClassifyR` sends the data set (or subsets of it) to feature selection and classification functions as a `DataFrame`. Either the input data is a `DataFrame` or is converted into one without loss of information.

.center[
![](images/matrixToDataFrame.png)
]

---

## DataFrame Container

.center[
![](images/MAEtoDataFrame.png)
]


---
## Cross-validation Overview

* Cross-validation is the procedure of selecting features and training a classifier on a set of samples and making predictions on a distinct set of samples.

--

* The function `runTests` manages cross-validation. `runTests` repeatedly calls `runTest` to perform a single iteration of training and testing.

--

* `runTest` may be used directly for a single training set and a single test set, an experimental design which some published studies have.

--

* There are many cross-validation designs commonly used in practice. `runTests` accepts a variety of customisations for the schemes.

---
## Cross-validation: Repeated Permute and *k*-Fold

The order of samples is repeatedly permuted and they are divided into *k* approximately equally-sized groups. Each group is used as the test set once. When complete, each sample is predicted as many times as the number of repetitions of sample permutation.

.center[
![](images/repeatFold.png)
]

This is the default scheme of `runTests`. By default, 100 permutations are each partitioned into five folds.

---
## Cross-validation: Repeated Permute and Split

The order of samples is repeatedly permuted and they are divided into two groups. Only one group is used as the test set (default: 25% of samples). When complete, each sample is predicted approximately as many times as the number of repetitions `\(\times\)` test set percentage.

.center[
![](images/permuteSplit.png)
]

---
## Cross-validation: Leave-`k`-Out

All possible combinations of *k* samples are chosen from all *n* samples to form the test set. Default value of *k* is 2.

.center[
![](images/leave2out.png)
]

For a moderately sized data set, any value of *k* &gt; 3 will not complete in a reasonable amount of time.

---
## Cross-validation: Leave-`k`-Out

For *k* = 1, each sample is predicted once.

For *k* = 2, each sample is predicted `\(n-1\)` times.

For *k* = 3, each sample is predicted `\((n-1) \times (n-2) / 2\)` times.

---
## Cross-validation: Ordinary k-fold

The samples are divided into *k* approximately equally-sized groups. Each group is used as the test set once. Default *k* is 5.

.center[
![](images/ordinaryK.png)
]

Because each sample is predicted once, there's no estimate of class prediction variability.

---
## Types of Change

A change between classes of mean, variability or distribution may be informative for predicting classes.

.center[
![](images/DMDVDD.png)
]


---
## Functions for Feature Selection

There are numerous functions provided for popular feature selection approaches. Feature selection by the included functions is typically based on a ranking of features, followed by choosing the top *p* features which give the best resubstitution error rate.

.center[
![](images/providedSelection.png)
]

---
## Resubstitution Error Rate for Feature Selection

- Resubstitution error rate is the error rate obtained when a classifier is trained on a set of samples (e.g. a training set during cross-validation) and predictions are made on the same set of samples.

--

- Provided functions operate by ranking features from largest to smallest difference between classes and choose a set of the top *p* features from a range of values of *p* which gives the best resubstitution error rate.

--

- Simply a heuristic which avoids computationally expensive nested cross-validation to choose features.

---
## Wrappers for Classification

There are a variety of functions implementing or wrapping popular classifiers.

.center[
![](images/providedClassifiers.png)
]

---
## Functions for Network-based Classification

Biological features don't work in isolation but are a part of large networks. Some common network-based classification algorithms are included with `ClassifyR`.

.center[
![](images/networkFunctions.png)
]

---

## Parameter Container Classes

A list of instances of parameter classes is provided to `runTests` to be applied to each iteration of cross validation. They specify the kind of data transformation, feature selection and classification to do.

1. `TransformParams` (optional): The first parameter is a function which transforms the values somehow. For example, `transParams &lt;- TransformParams(subtractFromLocation)`.
--
&lt;br&gt;
2. `SelectParams` (optional): The first parameter is a function which returns a subset of feature names. For example, `selParams &lt;- SelectParams(tTestSelection)`.
--
&lt;br&gt;
3. `TrainParams` : The first parameter is a function which takes as input a `DataFrame` and either a factor vector of classes or a `DataFrame` column name containing them and trains a classifier. It might also do the predictions on the test set and accept the test set in the third parameter position.&lt;br&gt;For example, `trainParams &lt;- TrainParams(naiveBayesKernel)`.
--
&lt;br&gt;
4. `PredictParams` : The first parameter is either a function which takes as input a trained model followed by the test set `DataFrame` and predicts classes and/or class scores or `NULL` if the training function also makes predictions. For example, `predParams &lt;- PredictParams(NULL)`.

---
## Classification Performance Evaluation

* Feature selection stability evaluates whether the selected features are consistent between iterations of cross validation.

* Many of the typical classification metrics may be calculated. Examples are accuracy, error rate, ROC plot. Most are applicable for any number of classes greater than two.

* **Sample-wise** accuracy and error-rate calculation allows the identification of samples which are consistently misclassified within a classification or across different classifications.

---

class: segue-red

# Part 2: Interactive Session Classifying AML Treatment Resistance

---

class: segue-red

# Part 3: Concluding Remarks

---

## Package Installation

1. Visit the package web page [https://bioconductor.org/packages/ClassifyR/](https://bioconductor.org/packages/ClassifyR/).

2. Simply copy and paste the commands from the Installation section into an active R session.

.center[
![](images/install.png)
]

---

## Vignettes

* A fully worked example on a recent asthma classification data set (*Scientific Reports*, 2018) using a couple of different classifiers and a variety of performance metrics is provided.

* A demonstration of how to create a wrapper function for the *k* Nearest Neighbours function.


```r
browseVignettes("ClassifyR")
```

.center[
![](images/vignetteList.png)
]

---

## Support Forum

A good way to ask questions and receive answers that may be useful to others.

.center[
![](images/forum.png)
]

.center[Visit &lt;a href="http://support.bioconductor.org" target="_blank"&gt;http://support.bioconductor.org&lt;/a&gt;]

---

# Acknowledgements

.columns-2[.content-box-gray[.bold[Sydney Bioinformatics and Biometrics]
- Prof. Jean Yang
- Dr. John Ormerod
- Dr. Kaushala Jayawardana (fmr.)
- Dr. Vivek Jayaswal (fmr.)
- Dr. Ellis Patrick
- Mr. Kevin Wang
- Ms. Yingxin Lin
]

.content-box-gray[.bold[Melanoma Institute of Australia]
- Prof. Graham Mann
- Dr. Sarah-Jane Schramm
]]

ClassifyR version 1 was developed while Dario Strbenac was funded by an Australian Postgraduate Award and Australian Research Council DP130100488.
&lt;br&gt;
ClassifyR version 2 was developed while Dario Strbenac received funding from Australian Research Council DP170100654.

---

# References

* Dario Strbenac, Graham J. Mann, John T. Ormerod and Jean Y.H. Yang (2015) [ClassifyR: an R package for performance assessment of classification with applications to transcriptomics](https://academic.oup.com/bioinformatics/article/31/11/1851/2365648), *Bioinformatics*, 31(11):1851-1853

* Dario Strbenac, Graham J. Mann, Jean Y.H. Yang and John T. Ormerod (2016) [Differential distribution improves gene selection stability and has competitive classification performance for patient survival](https://academic.oup.com/nar/article/44/13/e119/2457601), *Nucleic Acids Research*, 44(13):e119.

* Ellis Patrick, Sarah-Jane Schramm, John T. Ormerod, Richard A. Scolyer, Graham J. Mann, Samuel Mueller, Jean Y. H. Yang (2017) [A multi-step classifier addressing cohort heterogeneity improves performance of prognostic biomarkers in three cancer types](http://www.oncotarget.com/index.php?journal=oncotarget&amp;page=article&amp;op=view&amp;path%5B%5D=13203&amp;path%5B%5D=41874), *Oncotarget*, 8(2):2807-2815.
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
